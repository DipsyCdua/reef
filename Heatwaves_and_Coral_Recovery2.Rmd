---
title: "Heatwaves_and_Coral_Recovery"
author: "Kunlei"
date: "2025-05-04"
output: html_document
---
```{r}
library(dplyr)
library(tidyr)
library(ggpubr)
library(DBI)
library(RPostgres)
library(RSQLite)
library(ranger)
library(ggplot2)
library(Metrics)
```

```{r}
sqlite_con <- dbConnect(RSQLite::SQLite(), "D:/R_studio_working_dir/DATA3888_group/Heatwaves and Coral Recovery Database (HeatCRD) SQLITE.db")
```

```{r}
con <- dbConnect(
  RPostgres::Postgres(),
  dbname = "Heatwaves and Coral Recovery",
  host = "localhost",
  port = 5432,
  user = "postgres",
  password = "magic123"
)
```

```{r}
# List SQLite tables
tables <- dbListTables(sqlite_con)

# For each table, read from SQLite and write to PostgreSQL
for (tbl in tables) {
  data <- dbReadTable(sqlite_con, tbl)
  dbWriteTable(con, tbl, data, overwrite = TRUE)
}
```

```{r}
for (tbl in tables) {
  cat("Table:", tbl, "\n")
  cols <- dbListFields(sqlite_con, tbl)
  print(cols)
  cat("\n")
}
```


```{r}
cmd <- "SELECT * FROM \"Query_6_Time_Series_Sites\" 
        LIMIT 5"
result <- dbGetQuery(con, cmd)
result
```

#join Site_Description_tbl and Sample_Event_tbl and cover_tbl and Thermal_Stress_tbl by sample_id
```{r}
joined_df <- dbGetQuery(con, '
  SELECT
    sd.*,
    se."Sample_ID",
    se."Date_Day",
    se."Date_Month",
    se."Date_Year",
    se."Depth" AS "Event_Depth",
    se."Comments" AS "Event_Comments",
    c."Percent_Hard_Coral_Cover",
    c."Comments" AS "Cover_Comments",
    ts."ClimSST",
    ts."Temperature_Kelvin",
    ts."Temperature_Mean",
    ts."Temperature_Minimum",
    ts."Temperature_Maximum",
    ts."Temperature_Kelvin_Standard_Deviation",
    ts."Windspeed",
    ts."SSTA",
    ts."SSTA_Mean",
    ts."SSTA_Minimum",
    ts."SSTA_Maximum",
    ts."SSTA_DHW",
    ts."TSA",
    ts."TSA_Mean",
    ts."TSA_DHWMean"
  FROM "Thermal_Stress_tbl" AS ts
  JOIN "Cover_tbl" AS c  ON ts."Sample_ID"  = c."Sample_ID"
  JOIN "Sample_Event_tbl" AS se ON c."Sample_ID"   = se."Sample_ID"
  JOIN "Site_Description_tbl" AS sd ON se."Site_ID" = sd."Site_ID"
  ORDER BY "Date_Year"
')

joined_df

```

```{r}
new_table_name <- "joined_coral_thermal_data"
dbWriteTable(con, new_table_name, joined_df, overwrite = TRUE)

cat("New table '", new_table_name, "' has been created in the database.\n", sep = "")
```


```{r}
# Create region classification
joined_df <- joined_df %>%
  mutate(Region = case_when(
    Latitude_Degrees > -15 ~ "Northern",
    Latitude_Degrees > -20 ~ "Central",
    TRUE ~ "Southern"
  ))

print(table(joined_df$Region))
```


```{r}
# Save joined data to database
dbWriteTable(con, "joined_coral_thermal_data", joined_df, overwrite = TRUE)
cat("\nNew table 'joined_coral_thermal_data' created successfully.\n")

# Get year range
year_range <- dbGetQuery(con, 'SELECT MAX("Date_Year"), MIN("Date_Year") FROM "joined_coral_thermal_data"')
cat("\nYear range in data:\n")
print(year_range)
```


```{r}
# Robust ENSO data loading function
load_enso_data <- function() {
  enso_url <- "https://www.cpc.ncep.noaa.gov/data/indices/soi"
  enso_text <- readLines(enso_url)
  
  # Find data section (skip headers)
  start_line <- which(grepl("^\\s*YEAR", enso_text))[1] + 1
  end_line <- which(enso_text == "")[1] - 1  # First empty line after data
  if(is.na(end_line)) end_line <- length(enso_text)
  
  # Process only valid data lines
  enso_lines <- enso_text[start_line:end_line]
  valid_lines <- grep("^\\s*\\d{4}(\\s+[-+]?\\d*\\.?\\d+){12}\\s*$", enso_lines, value = TRUE)
  
    # Read data with error handling
  enso_data <- read.table(
    text = valid_lines,
    col.names = c("Year", month.abb),
    fill = TRUE  # Fill missing values if any
  )
  
  enso_data %>%
    pivot_longer(-Year, names_to = "Month", values_to = "SOI") %>%
    mutate(
      Month_Num = match(Month, month.abb),
      Date = as.Date(paste(Year, Month_Num, "01", sep = "-"))
    ) %>%
    filter(!is.na(SOI))  # Remove NA values
}
```


```{r}
enso_long <- load_enso_data()
```


```{r}
# Merge with coral data
full_data <- joined_df %>%
  left_join(enso_long, by = c("Date_Year" = "Year", "Date_Month" = "Month_Num"))

# Correlation analysis
cor_result <- cor.test(full_data$SSTA_DHW, full_data$SOI, use = "complete.obs")
print(paste("Correlation between DHW and SOI:", round(cor_result$estimate, 4)))
```

```{r}
# Visualization
library(ggplot2)
ggplot(full_data, aes(x = SOI, y = SSTA_DHW)) +
  geom_point(color = "lightblue",alpha = 0.6) +
  geom_smooth(color = "lightpink",method = "lm") +
  stat_cor(method = "pearson", size = 3, label.x =0, label.y = Inf, vjust = 1.5) +
  labs(title = "Relationship Between DHW and ENSO Index",
       x = "Southern Oscillation Index (SOI)",
       y = "Degree Heating Weeks (DHW)") +
  theme_minimal()

```



```{r}

# Shiny App
library(shiny)
library(leaflet)

ui <- fluidPage(
  titlePanel("Coral Reef Thermal Stress Visualization"),
  sidebarLayout(
    sidebarPanel(
      selectInput("region", "Select Region", 
                 choices = c("Northern", "Central", "Southern")),
      sliderInput("year", "Select Year",
                 min = min(joined_df$Date_Year),
                 max = max(joined_df$Date_Year),
                 value = median(joined_df$Date_Year))
    ),
    mainPanel(
      leafletOutput("map"),
      plotOutput("trend")
    )
  )
)

```

```{r}
server <- function(input, output) {
  filtered <- reactive({
    joined_df %>%
      filter(Region == input$region, Date_Year == input$year)
  })
  
  output$map <- renderLeaflet({
    data <- filtered()
    leaflet(data) %>%
      addTiles() %>%
      addCircleMarkers(
        lng = ~Longitude_Degrees,
        lat = ~Latitude_Degrees,
        color = ~colorNumeric("YlOrRd", SSTA_DHW)(SSTA_DHW),
        radius = 5,
        popup = ~paste("DHW:", round(SSTA_DHW, 2))
      )
  })
  
  output$trend <- renderPlot({
    data <- joined_df %>% filter(Region == input$region)
    ggplot(data, aes(Date_Year, SSTA_DHW)) +
      geom_line() +
      labs(title = paste("DHW Trend in", input$region, "Region"),
           x = "Year", y = "Degree Heating Weeks")
  })
}
```

```{r}
shinyApp(ui, server)
```

```{r}
# install.packages("ranger")
```


```{r}

required_columns <- c("Site_ID", "Date_Year", "Date_Month", "SOI", "SSTA_DHW", 
                     "Latitude_Degrees", "Longitude_Degrees", "Region", 
                     "Distance_to_shore", "Temperature_Mean")
stopifnot(all(required_columns %in% names(full_data)))

full_data <- full_data %>%
  arrange(Site_ID, Date_Year, Date_Month) %>%
  group_by(Site_ID) %>%
  mutate(
    SOI_lag3 = lag(SOI, 3), 
    DHW_lag1 = lag(SSTA_DHW, 1)
  ) %>%
  ungroup() %>%
  mutate(
    Season = case_when(
      Date_Month %in% 3:5 ~ "Autumn",
      Date_Month %in% 6:8 ~ "Winter",
      Date_Month %in% 9:11 ~ "Spring",
      TRUE ~ "Summer"
    )
  ) %>%
  filter(!is.na(SOI_lag3))

train_data <- full_data %>% filter(Date_Year < 2015)
test_data <- full_data %>% filter(Date_Year >= 2015)

stopifnot(nrow(train_data) > 0)
stopifnot(nrow(test_data) > 0)

features <- c("SOI", "SOI_lag3", "Region", "Season", 
             "Distance_to_shore", "Temperature_Mean")
target <- "SSTA_DHW"

set.seed(3888)
rf_model <- ranger(
  formula = paste(target, "~", paste(features, collapse = "+")),
  data = train_data,
  importance = "permutation",
  num.trees = 500,
  verbose = TRUE
)

test_data$predicted_DHW <- predict(rf_model, data = test_data)$predictions

cat("RMSE:", rmse(test_data$SSTA_DHW, test_data$predicted_DHW), "\n")
cat("R-squared:", cor(test_data$SSTA_DHW, test_data$predicted_DHW)^2, "\n")


```
Prediction
```{r}
missing_dhw <- sum(is.na(full_data$SSTA_DHW))
cat("Number of missing values in SSTA_DHW:", missing_dhw, "\n")

sapply(full_data[, features], function(x) sum(is.na(x))) %>% 
  print()

model_data <- full_data %>%
  drop_na(SSTA_DHW, all_of(features))

cat("Remaining rows after handling missing values:", nrow(model_data), "\n")

```

```{r}

train_data <- model_data %>% filter(Date_Year < 2015)
test_data <- model_data %>% filter(Date_Year >= 2015)

stopifnot(nrow(train_data) > 100) 
stopifnot(nrow(test_data) > 30) 

set.seed(3888)
rf_model <- ranger(
  formula = paste("SSTA_DHW ~", paste(features, collapse = "+")),
  data = train_data,
  importance = "permutation",
  num.trees = 500,
  replace = TRUE,     
  sample.fraction = 0.8,
  verbose = TRUE
)

```

```{r}

test_data <- test_data %>% drop_na(SSTA_DHW, all_of(features))

test_data$predicted_DHW <- predict(rf_model, data = test_data)$predictions

cat("Model Performance:\n")
cat("RMSE:", sqrt(mean((test_data$SSTA_DHW - test_data$predicted_DHW)^2)), "\n")
cat("R-squared:", cor(test_data$SSTA_DHW, test_data$predicted_DHW)^2, "\n")

```


```{r}
ggplot(test_data, aes(x = predicted_DHW, y = SSTA_DHW - predicted_DHW)) +
  geom_point(alpha = 0.6) +
  geom_hline(yintercept = 0, linetype = "dashed", color = "lightpink") +
  labs(title = "Residual Plot", 
       x = "Predicted DHW", 
       y = "Residuals") +
  theme_minimal()
```











